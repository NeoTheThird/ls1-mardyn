#ifndef WARPBLOCKCELLPROCESSOR_CUM__
#define WARPBLOCKCELLPROCESSOR_CUM__

#include <host_defines.h>

#include "util.cum"

#include "cellInfo.cum"
#include "moleculeStorage.cum"
#include "util/locks.cum"
#include "util/ringQueue.cum"

#define WBM_QUEUE_SIZE 4

namespace WBDP {

struct WarpBlockInfo {
	CellInfo cell;
	uint cellIndex;
	uint warpBlockIndex;

	__device__ WarpBlockInfo() {}
	__device__ WarpBlockInfo( const CellInfo cell, uint cellIndex, uint warpBlockIndex ) : cell( cell ), cellIndex( cellIndex ), warpBlockIndex( warpBlockIndex ) {}
};

struct WarpBlockPairInfo {
	WarpBlockInfo warpBlockA;
	CellInfo cellB;

	__device__ WarpBlockPairInfo() {}
	__device__ WarpBlockPairInfo( WarpBlockInfo warpBlockA, CellInfo  cellB ) : warpBlockA( warpBlockA ), cellB( cellB ) {}
	__device__ WarpBlockPairInfo( const WarpBlockPairInfo &other ) : warpBlockA( other.warpBlockA ), cellB( other.cellB ) {}
};

struct ThreadBlockInfo {
	RingQueue<WarpBlockPairInfo, WBM_QUEUE_SIZE> warpJobQueue[NUM_WARPS];

	// bitmask for
	volatile uint jobIdleSignal;
	volatile bool hasMoreJobs;

	// global lock
	__device__ ThreadBlockInfo() : hasMoreJobs( true ), jobIdleSignal( 0 ) {}
};

template<class SpecificScheduler>
class SchedulerTemplate {
private:
	Lock::Mutex globalMutex;

public:
#if 1
#warning semaphore scheduler
	// returns false if the specific warp block should terminate
		__device__ __noinline__ void scheduleWarpBlocks( ThreadBlockInfo & __restrict__ threadBlockInfo ) {
			const uint warpBit = 1 << threadIdx.y;

			// only thread 0 of the current warp runs here
			if( threadIdx.x == 0 ) {
				// signal that this warp is idle right now
				atomicOr( (uint*) &threadBlockInfo.jobIdleSignal, warpBit );

				WARP_PRINTF( "globalMutex entering\n" );

				// wait until it's our turn for the lock
				bool haveLock = globalMutex.lock( (uint*) &threadBlockInfo.jobIdleSignal, warpBit );

				// if I dont have the lock the signal has been reset
				if( haveLock ) {
					WARP_PRINTF( "globalMutex lock\n" );

					if( threadBlockInfo.jobIdleSignal ) {
						// create a local copy of warpWaiting
						const uint snapshoptJobIdleSignal = threadBlockInfo.jobIdleSignal;

						assignJobs( threadBlockInfo, snapshoptJobIdleSignal );

						WARP_PRINTF( "jobs assigned\n" );

						__threadfence_block();

						// reset the assigned warpWaiting bits
						// this is the semaphore signal for the other warps in the thread block
						atomicXor( (uint*) &threadBlockInfo.jobIdleSignal, snapshoptJobIdleSignal );
					}
					else {
						WARP_PRINTF( "no idle flags\n" );
					}

					WARP_PRINTF( "globalMutex unlock\n" );

					// release our global lock
					globalMutex.unlock();
				}
				else {
					//WARP_PRINTF( "globalSemaphore signaled\n" );
				}
			}
		}
#else
	// safe implementation

	// returns false if the specific warp block should terminate
	__device__ __noinline__ void scheduleWarpBlocks( ThreadBlockInfo & __restrict__ threadBlockInfo ) {
		// only thread 0 of the current warp runs here
		if( threadIdx.x == 0 ) {
			// wait until it's our turn for the lock
			globalMutex.lock();

			WARP_PRINTF( "globalMutex enter\n" );

			// assign jobs
			assignJobs( threadBlockInfo, threadIdx.y );

			WARP_PRINTF( "globalMutex leave\n" );
			__threadfence();

			// release our global lock
			// no sync needed since we are the only ones to access it
			globalMutex.unlock();
		}
	}
#endif


	__device__ void assignJobs( ThreadBlockInfo & __restrict__ threadBlockInfo, uint idleJobMask ) {
		const uint idleWarpCount = __popc( idleJobMask );
		//WARP_PRINTF( "assigning jobs for %i warps\n", idleWarpCount );

		for( uint warpJobs = 0 ; warpJobs <  WBM_QUEUE_SIZE ; warpJobs++ ) {
			uint warpMask = idleJobMask;
			for( uint warpCount = 0 ; warpCount < idleWarpCount ; warpCount++ ) {
				int warpIndex = __ffs( warpMask ) - 1;

				// assign jobs
				if( !reinterpret_cast<SpecificScheduler *>(this)->nextWarpBlock() ) {
					threadBlockInfo.hasMoreJobs = false;
					return;
				}

				const WarpBlockPairInfo job = reinterpret_cast<SpecificScheduler *>(this)->getWarpBlock();
				threadBlockInfo.warpJobQueue[warpIndex].push( job );

				//WARP_PRINTF("assignJobs: %i, %i\n", warpInfos.warps[warpIndex].warpBlockA.cellIndex, warpInfos.warps[warpIndex].warpBlockA.warpBlockIndex );

				// remove the updated warp bit from warpIndex
				warpMask ^= 1 << warpIndex;
			}
		}
	}
};

class CellScheduler : public SchedulerTemplate<CellScheduler> {
private:
	int jobIndex;

	int cellIndex;
	CellInfoEx cell;
	uint numWarpBlocks;
	uint warpBlockIndex;

public:
	__device__ WarpBlockPairInfo getWarpBlock() {
		return WarpBlockPairInfo( WarpBlockInfo( cell, cellIndex, warpBlockIndex ), cell );
	}

	__device__ bool nextWarpBlock() {
		if( ++warpBlockIndex < numWarpBlocks ) {
			return true;
		}

		do {
			if( ++jobIndex >= DomainTraverser::numJobs ) {
				return false;
			}

			cellIndex = DomainTraverser::getInnerCellIndexFromJobIndex(jobIndex);
			cell = CellInfoEx( cellInfoFromCellIndex( cellIndex ) );
		}
		while( cell.length == 0 );

		numWarpBlocks = cell.getWarpCount();
		warpBlockIndex = 0;

		//WARP_PRINTF( "nextWarpBlock: %i\n", cellIndex );
		return true;
	}

public:
	__device__ CellScheduler() : jobIndex( -1 ), cellIndex( 0 ), cell( CellInfo( 0, 0 ) ), numWarpBlocks( 0 ), warpBlockIndex( 0 ) {}
};

class CellPairScheduler : public SchedulerTemplate<CellPairScheduler> {
private:
	int jobIndex;

	int cellIndexA;
	CellInfoEx cellA;
	uint numWarpBlocksA;
	uint warpBlockIndexA;

	CellInfoEx cellB;

public:
	__device__ WarpBlockPairInfo getWarpBlock() {
		return WarpBlockPairInfo( WarpBlockInfo( cellA, cellIndexA, warpBlockIndexA ), cellB );
	}

	__device__ bool nextWarpBlock() {
		if( ++warpBlockIndexA < numWarpBlocksA) {
			return true;
		}

		do {
			jobIndex++;

			if( jobIndex >= 2 * DomainTraverser::numJobs ) {
				return false;
			}

			const int originalCellIndex = DomainTraverser::getCellIndexFromJobIndex( jobIndex % DomainTraverser::numJobs );
			const int neighborCellIndex = DomainTraverser::getNeighborCellIndex( originalCellIndex );

			int cellIndexB;
			if( jobIndex < DomainTraverser::numJobs ) {
				cellIndexA = originalCellIndex;
				cellIndexB = neighborCellIndex;
			}
			else {
				cellIndexA = neighborCellIndex;
				cellIndexB = originalCellIndex;
			}
			cellA = CellInfoEx( cellInfoFromCellIndex( cellIndexA ) );
			cellB = CellInfoEx( cellInfoFromCellIndex( cellIndexB ) );
		}
		while( cellA.length == 0 || cellB.length == 0 );

		numWarpBlocksA = cellA.getWarpCount();
		warpBlockIndexA = 0;
		return true;
	}

public:
	__device__ CellPairScheduler()
		: jobIndex( -1 ), cellA( CellInfo( 0, 0 ) ), cellB( CellInfo( 0, 0 ) ),
		  cellIndexA( 0 ), numWarpBlocksA( 0 ), warpBlockIndexA( 0 ) {}
};

template<class MoleculeStorage, MoleculeStorage &moleculeStorage>
struct DomainProcessor {
	typedef Molecule<MoleculeStorage, moleculeStorage> StorageMolecule;

	// unified for cells and cell pairs
	__device__ __noinline__ void processCellPair( WarpBlockPairInfo warpBlockPairInfo ) {
		WARP_PRINTF( "processing cell %i block %i/%i and molecules %i - %i\n", warpBlockPairInfo.warpBlockA.cellIndex, warpBlockPairInfo.warpBlockA.warpBlockIndex, iceil( warpBlockPairInfo.warpBlockA.cell.endIndex - warpBlockPairInfo.warpBlockA.cell.startIndex, WARP_SIZE), warpBlockPairInfo.cellB.startIndex, warpBlockPairInfo.cellB.endIndex );

		WarpBlockInfo warpBlockA = warpBlockPairInfo.warpBlockA;

		const uint indexA = warpBlockA.cell.getWarpOffset(warpBlockA.warpBlockIndex) + threadIdx.x;
		if( indexA >= warpBlockA.cell.endIndex ) {
			return;
		}

		StorageMolecule moleculeA;
		moleculeA.load(indexA);

		// now loop over all molecules in this cell
		CellInfo cellB = warpBlockPairInfo.cellB;

#ifdef CUDA_HW_CACHE_ONLY
		for( int indexB = cellB.startIndex ; indexB < cellB.endIndex ; indexB++ ) {
			StorageMolecule moleculeB;
			moleculeB.load(indexB);

			if( indexA != indexB ) {
				MoleculePairHandler::process( threadIdx.x + threadIdx.y * WARP_SIZE, moleculeA, moleculeB );
			}
		}
#else
		for( int indexB = cellB.startIndex ; indexB < cellB.endIndex ; indexB++ ) {
			StorageMolecule moleculeB(indexB);

			if( indexA != indexB ) {
				MoleculePairHandler::process( threadIdx.x + threadIdx.y * WARP_SIZE, moleculeA, moleculeB );
			}
		}
#endif

		moleculeA.store();

	}
};

}

#endif
