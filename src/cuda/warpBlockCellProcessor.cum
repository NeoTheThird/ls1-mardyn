#ifndef WARPBLOCKCELLPROCESSOR_CUM__
#define WARPBLOCKCELLPROCESSOR_CUM__

#include <host_defines.h>

#include "util.cum"

#include "cellInfo.cum"
#include "moleculeStorage.cum"
#include "locks.cum"

// TODO: rename to WBCP
namespace WarpBlockMode {

template< uint warpBlockCount, typename WarpJobDescriptor >
struct WarpInfos { // TODO: rename ThreadBlockInfo
	WarpJobDescriptor warps[ warpBlockCount ];

	// bitmask for
	volatile uint warpIdle; // TODO: rename to warpIdle ie no current job
	volatile uint warpAlive;

	// global lock
	uint globalTicket;

	WarpInfos() : warpIdle( 0 ), warpAlive( (1 << warpBlockCount) - 1 ), globalTicket( 0 ) {}
};

#define __syncwarp()

template<uint warpBlockCount, typename WarpJobDescriptor, template<uint> class SpecificScheduler>
class GenericScheduler {
private:
	Lock::Mutex globalMutex;

public:
#if 1
	// returns false if the specific warp block should terminate
		__device__ __noinline__ bool scheduleWarpBlocks( WarpInfos<warpBlockCount, WarpJobDescriptor> & __restrict__ warpInfos ) {
			const uint warpBit = 1 << threadIdx.y;

			// only thread 0 of the current warp runs here
			if( threadIdx.x == 0 ) {
				// signal that this warp is idle right now
				atomicOr( (uint*) &warpInfos.warpIdle, warpBit );

				WARP_PRINTF( "globalMutex entering\n" );

				// wait until it's our turn for the lock
				bool haveLock = globalMutex.lock( (uint*) &warpInfos.warpIdle, warpBit );

				// if I dont have the lock the signal has been reset
				if( haveLock ) {
					WARP_PRINTF( "globalMutex lock\n" );

					if( warpInfos.warpIdle ) {
						// create a local copy of warpWaiting
						const uint myWarpIdle = warpInfos.warpIdle;

						// assign jobs
						const uint myWarpStarved = assignJobs( warpInfos, myWarpIdle );

						WARP_PRINTF( "jobs assigned\n" );

						// update the alive bitmask
						warpInfos.warpAlive ^= myWarpStarved;

						// reset the assigned warpWaiting bits
						// this is the semaphore signal for the other warps in the thread block
						atomicXor( (uint*) &warpInfos.warpIdle, myWarpIdle );

						__threadfence_block();
					}
					else {
						WARP_PRINTF( "no idle flags\n" );
					}

					WARP_PRINTF( "globalMutex unlock\n" );

					// release our global lock
					globalMutex.unlock();

					__threadfence_block();
				}
				else {
					//WARP_PRINTF( "globalSemaphore signaled\n" );
				}
			}

			// all threads in a warp are synchronized implicitly
			 __syncwarp();
			return (warpInfos.warpAlive & warpBit) != 0;
		}
#else
	// safe implementation

	// returns false if the specific warp block should terminate
	__device__ __noinline__ bool scheduleWarpBlocks( WarpInfos<warpBlockCount, WarpJobDescriptor> & __restrict__ warpInfos ) {
		const uint warpBit = 1 << threadIdx.y;

		// only thread 0 of the current warp runs here
		if( threadIdx.x == 0 ) {
			// wait until it's our turn for the lock
			globalMutex.lock();

			//WARP_PRINTF( "globalMutex enter\n" );

			// assign jobs
			const uint myWarpStarved = assignJobs( warpInfos, warpBit );

			// update the alive bitmask
			warpInfos.warpAlive ^= myWarpStarved;

			//WARP_PRINTF( "globalMutex leave\n" );
			__threadfence();

			// release our global lock
			// no sync needed since we are the only ones to access it
			globalMutex.unlock();
		}

		// all threads in a warp are synchronized implicitly
		 __syncwarp();
		return (warpInfos.warpAlive & warpBit) != 0;
	}
#endif


	__device__ uint assignJobs( WarpInfos<warpBlockCount, WarpJobDescriptor> & __restrict__ warpInfos, uint myWarpIdle ) {
		// how many warps do we have to assign jobs to?
		const int idleWarpCount = __popc( myWarpIdle );

		//WARP_PRINTF( "assigning jobs for %i warps\n", idleWarpCount );

		int warpCount;
		for( warpCount = 0 ; warpCount < idleWarpCount ; warpCount++ ) {
			if( !reinterpret_cast<SpecificScheduler<warpBlockCount> *>(this)->nextWarpBlock() ) {
				break;
			}

			int warpIndex = __ffs( myWarpIdle ) - 1;
			warpInfos.warps[warpIndex] = reinterpret_cast<SpecificScheduler<warpBlockCount> *>(this)->getWarpBlock();
			//WARP_PRINTF("assignJobs: %i, %i\n", warpInfos.warps[warpIndex].warpBlockA.cellIndex, warpInfos.warps[warpIndex].warpBlockA.warpBlockIndex );
			// remove the updated warp bit from warpIndex
			myWarpIdle ^= 1 << warpIndex;
		}

		// no more warps => all remaining idle warps need to die
		return myWarpIdle;
	}
};

struct WarpBlockInfo {
	CellInfo cell;
	uint cellIndex;
	uint warpBlockIndex;

	__device__ WarpBlockInfo() {}
	__device__ WarpBlockInfo( const CellInfo cell, uint cellIndex, uint warpBlockIndex ) : cell( cell ), cellIndex( cellIndex ), warpBlockIndex( warpBlockIndex ) {}
};

struct WarpBlockPairInfo {
	WarpBlockInfo warpBlockA;
	CellInfo cellB;

	__device__ WarpBlockPairInfo() {}
	__device__ WarpBlockPairInfo( WarpBlockInfo warpBlockA, CellInfo  cellB ) : warpBlockA( warpBlockA ), cellB( cellB ) {}
};

template<uint warpBlockCount>
class CellScheduler : public GenericScheduler<warpBlockCount, WarpBlockPairInfo, CellScheduler> {
private:
	int jobIndex;

	int cellIndex;
	CellInfoEx cell;
	uint numWarpBlocks;
	uint warpBlockIndex;

public:
	__device__ WarpBlockPairInfo getWarpBlock() {
		return WarpBlockPairInfo( WarpBlockInfo( cell, cellIndex, warpBlockIndex ), cell );
	}

	__device__ bool nextWarpBlock() {
		if( ++warpBlockIndex < numWarpBlocks ) {
			return true;
		}

		do {
			if( ++jobIndex >= PairTraverser::numJobs ) {
				return false;
			}

			cellIndex = PairTraverser::getInnerCellIndexFromJobIndex(jobIndex);
			cell = CellInfoEx( cellInfoFromCellIndex( cellIndex ) );
		}
		while( cell.length == 0 );

		numWarpBlocks = iceil( cell.length, WARP_SIZE );
		warpBlockIndex = 0;

		//WARP_PRINTF( "nextWarpBlock: %i\n", cellIndex );
		return true;
	}

public:
	__device__ CellScheduler() : jobIndex( -1 ), cellIndex( 0 ), cell( CellInfo( 0, 0 ) ), numWarpBlocks( 0 ), warpBlockIndex( 0 ) {}
};

template<uint warpBlockCount>
class CellPairScheduler : public GenericScheduler<warpBlockCount, WarpBlockPairInfo, CellPairScheduler> {
private:
	int jobIndex;

	int cellIndexA;
	CellInfoEx cellA;
	uint numWarpBlocksA;
	uint warpBlockIndexA;

	CellInfoEx cellB;

public:
	__device__ WarpBlockPairInfo getWarpBlock() {
		return WarpBlockPairInfo( WarpBlockInfo( cellA, cellIndexA, warpBlockIndexA ), cellB );
	}

	__device__ bool nextWarpBlock() {
		if( ++warpBlockIndexA < numWarpBlocksA) {
			return true;
		}

		do {
			jobIndex++;

			if( jobIndex >= 2 * PairTraverser::numJobs ) {
				return false;
			}

			const int originalCellIndex = PairTraverser::getCellIndexFromJobIndex( jobIndex % PairTraverser::numJobs );
			const int neighborCellIndex = PairTraverser::getNeighborCellIndex( originalCellIndex );

			if( jobIndex < PairTraverser::numJobs ) {
				cellIndexA = originalCellIndex;
				cellA = CellInfoEx( cellInfoFromCellIndex( originalCellIndex) );
				cellB = CellInfoEx( cellInfoFromCellIndex( neighborCellIndex ) );
			}
			else {
				cellIndexA = neighborCellIndex;
				cellA = CellInfoEx( cellInfoFromCellIndex( neighborCellIndex ) );
				cellB = CellInfoEx( cellInfoFromCellIndex( originalCellIndex ) );
			}
		}
		while( cellA.length == 0 || cellB.length == 0 );

		numWarpBlocksA = iceil( cellA.length, WARP_SIZE );
		warpBlockIndexA = 0;
		return true;
	}

public:
	__device__ CellPairScheduler()
		: jobIndex( -1 ), cellA( CellInfo( 0, 0 ) ), cellB( CellInfo( 0, 0 ) ),
		  cellIndexA( 0 ), numWarpBlocksA( 0 ), warpBlockIndexA( 0 ) {}
};

#if 0
// works correctly lock-free assuming there is exactly one consumer and one producer
template<uint size>
class WarpJobManager {
private:
	uint scheduledJobsCount;
	uint finishedJobsCount;

	bool terminate;

	// TODO: make this non-interleaved
	WarpJob jobs[size];

public:
	void startJob() {
		while( scheduledJobsCount <= finishedJobsCount ) {
			; // spin
		}
	}

	WarpJob getJob() const {
		return jobs[ finishedJobsCount /* + 1 - 1 */ % size ];
	}

	void finishJob() {
		finishedJobsCount++;
	}

	bool addJob( WarpJob job ) {
		if( finishedJobsCount + size > scheduledJobsCount ) {
			jobs[ scheduledJobsCount % size ] = job;
			scheduledJobsCount++;

			return true;
		}
		return false;
	}
};
#endif

template<uint warpBlockCount, class Molecule, class MoleculeStorage, class MoleculePairHandler>
struct CellProcessor {
	MoleculeStorage & __restrict__ moleculeStorage;
	MoleculePairHandler & __restrict__ moleculePairHandler;

	__device__ CellProcessor( MoleculeStorage & __restrict__ moleculeStorage, MoleculePairHandler & __restrict__ moleculePairHandler )
		: moleculeStorage( moleculeStorage ), moleculePairHandler( moleculePairHandler ) {}

	// unified for cells and cell pairs
	__device__ __noinline__ void processCellPair( WarpBlockPairInfo warpBlockPairInfo ) {
		WARP_PRINTF( "processing cell %i block %i/%i and molecules %i - %i\n", warpBlockPairInfo.warpBlockA.cellIndex, warpBlockPairInfo.warpBlockA.warpBlockIndex, iceil( warpBlockPairInfo.warpBlockA.cell.endIndex - warpBlockPairInfo.warpBlockA.cell.startIndex, WARP_SIZE), warpBlockPairInfo.cellB.startIndex, warpBlockPairInfo.cellB.endIndex );

		WarpBlockInfo warpBlockA = warpBlockPairInfo.warpBlockA;

		const uint indexA = warpBlockA.cell.startIndex + warpBlockA.warpBlockIndex * WARP_SIZE + threadIdx.x;
		if( indexA >= warpBlockA.cell.endIndex ) {
			return;
		}

		Molecule moleculeA;
		moleculeStorage.get( indexA, moleculeA );

		// now loop over all molecules in this cell
		CellInfo cellB = warpBlockPairInfo.cellB;

		for( int indexB = cellB.startIndex ; indexB < cellB.endIndex ; indexB++ ) {
			if( indexA == indexB ) {
				continue;
			}

			Molecule moleculeB;
			// TODO: add getU that uses an ldu asm block to load it!
			moleculeStorage.get( indexB, moleculeB );

			moleculePairHandler.process( threadIdx.x + threadIdx.y * WARP_SIZE, moleculeA, moleculeB );
		}

		moleculeStorage.set( indexA, moleculeA );
	}
};

}

#endif
