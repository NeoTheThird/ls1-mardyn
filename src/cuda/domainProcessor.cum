#include <host_defines.h>

#include "util.cum"

#include "cellInfo.cum"

// exactly one thread pro block
template<class MoleculeStorage, MoleculeStorage &moleculeStorage>
struct ReferenceCellProcessor {
	typedef Molecule< MoleculeStorage, moleculeStorage > StorageMolecule;

	__device__ void processCellPair(
			const int threadIndex, const CellInfo & __restrict__ cellA, const CellInfo & __restrict__ cellB
		) {
		for( uint indexA = cellA.startIndex ; indexA < cellA.endIndex ; indexA++ ) {
			StorageMolecule moleculeA(indexA);

			for( uint indexB = cellB.startIndex ; indexB < cellB.endIndex ; indexB++ ) {
				StorageMolecule moleculeB(indexB);

				MoleculePairHandler::process( 0, moleculeA, moleculeB );

				moleculeB.store();
			}
			moleculeA.store();
		}
	}

	__device__ void processCell(
			const int threadIndex, const CellInfo & __restrict__ cell
		) {
		for( uint indexA = cell.startIndex ; indexA < cell.endIndex ; indexA++ ) {
			StorageMolecule moleculeA(indexA);

			for( uint indexB = cell.startIndex ; indexB < indexA; indexB++ ) {
				StorageMolecule moleculeB(indexB);

				MoleculePairHandler::process( 0, moleculeA, moleculeB );

				moleculeB.store();
			}
			moleculeA.store();
		}
	}
};

template<uint blockSize, uint localStorageBlockSize,
class MoleculeStorage, MoleculeStorage &moleculeStorage,
class MoleculeLocalStorage, MoleculeLocalStorage &moleculeLocalStorage>
struct HighDensityDomainProcessor {

	enum BlockPairType {
		BPT_UNRELATED,
		BPT_SAME_BLOCK   // implies same cell
	};

	typedef Molecule<MoleculeStorage, moleculeStorage> StorageMolecule;
	typedef Molecule<MoleculeLocalStorage, moleculeLocalStorage> LocalStorageMolecule;

	__device__ void processMoleculePair(int threadIndex, uint localIndexB, StorageMolecule & __restrict__ moleculeA) {
		LocalStorageMolecule moleculeB;
		moleculeB.load(localIndexB);

		MoleculePairHandler::process( threadIndex, moleculeA, moleculeB );

		moleculeB.store();
	}

	// componentLJCenterOffsetFromFirst is only used when blockPairType != BPT_UNRELATED
	template< BlockPairType blockPairType >
	__device__ __noinline__ void processBlock(
			const int threadIndex,
			const uint numMoleculesInBlockA,
			const uint numMoleculesInBlockB,
			const uint blockOffsetB,
			StorageMolecule & __restrict__ moleculeA
			) {
		const uint indexB = blockOffsetB + threadIndex;
		// load B data into cache
		if( threadIndex < numMoleculesInBlockB ) {
			moleculeLocalStorage.load( threadIndex, indexB );
		}

		// make sure all molecules have been written into the cache
		// before any one thread tries to access the cache
		// no __syncthreads() needed here, because at first we work on data from the current warp, so its automatically synched

		const uint localIndexA = threadIndex;

		// process block
#if NUM_WARPS == 1
		for( uint moleculeShiftIndex = 0 ; moleculeShiftIndex < WARP_SIZE ; moleculeShiftIndex++ ) {
			const uint localIndexB = (threadIdx.x + moleculeShiftIndex) % WARP_SIZE;

			// only do something when there is a molecule in A and a molecule in B to interact with
			if( localIndexA >= numMoleculesInBlockA || localIndexB >= numMoleculesInBlockB ) {
				continue;
			}

			// if we're not inside the same warp, process all WARP_SIZE * WARP_SIZE pairs inside the warp
			// otherwise only process the lower half
			// indexA >= indexB <=> localIndexA + blockOffsetA >= localIndexB + blockOffsetB <=> localIndexA >= localIndexB
			// (this only works for NUM_WARPS == NUM_LOCAL_STORAGE_WARPS!!!)
			if( blockPairType == BPT_SAME_BLOCK && localIndexB >= localIndexA ) {
				continue;
			}

#	ifndef CUDA_HW_CACHE_ONLY
			processMoleculePair( threadIndex, localIndexB, moleculeA );
#	else
			processMoleculePair( threadIndex, blockOffsetB + localIndexB, moleculeA );
#	endif
		}
#else
#	if 1
		/* divide the block into warp blocks
		 * each warp of the thread block (corresponds to a warp block of block A) interacts with
		 * one unique warp block of block B
		 *
		 * if there are more warp blocks in block B than block A,
		 * we need to iterate #warp blocks many times in B
		 *
		 * if there are more warp blocks in block A than block B,
		 * we need to iterate #warp blocks many time in A
		 */
		const uint numWarpBlocks = iceil( max( numMoleculesInBlockA, numMoleculesInBlockB ), WARP_SIZE );
		const uint numWarpBlocksInBlockB = iceil( numMoleculesInBlockB, WARP_SIZE );

		for( uint warpShiftIndex = 0 ; warpShiftIndex < numWarpBlocks ; warpShiftIndex++ ) {
			const uint warpBlockIndexB = (threadIdx.y + warpShiftIndex) % numWarpBlocks;
			const uint warpBlockOffsetB = warpBlockIndexB * WARP_SIZE;

			for( uint moleculeShiftIndex = 0 ; moleculeShiftIndex < WARP_SIZE ; moleculeShiftIndex++ ) {
				const uint localIndexB = warpBlockOffsetB + ((threadIdx.x + moleculeShiftIndex) % WARP_SIZE);

				// only do something when there is a molecule in A and a molecule in B to interact with
				if( localIndexA >= numMoleculesInBlockA || localIndexB >= numMoleculesInBlockB ) {
					continue;
				}

				// if we're not inside the same warp, process all WARP_SIZE * WARP_SIZE pairs inside the warp
				// otherwise only process the lower half
				// indexA >= indexB <=> localIndexA + blockOffsetA >= localIndexB + blockOffsetB <=> localIndexA >= localIndexB
				// (this only works for NUM_WARPS == NUM_LOCAL_STORAGE_WARPS!!!)
				if( blockPairType == BPT_SAME_BLOCK && localIndexB >= localIndexA ) {
					continue;
				}

#		ifndef CUDA_HW_CACHE_ONLY
				processMoleculePair( threadIndex, localIndexB, moleculeA );
#		else
				processMoleculePair( threadIndex, blockOffsetB + localIndexB, moleculeA );
#		endif
			}

			// sync all warps, so that no two different warps will try to access the same warp data block
			__syncthreads();
		}
#	else
		uint numMolecules = max( numMoleculesInBlockA, numMoleculesInBlockB );
		for( uint shiftIndex = 0 ; shiftIndex < numMolecules ; shiftIndex++ ) {
			uint localIndexB = (threadIndex + shiftIndex) % numMolecules;

			__syncthreads();

			// only do something when there is a molecule in A and a molecule in B to interact with
			if( localIndexA >= numMoleculesInBlockA || localIndexB >= numMoleculesInBlockB ) {
				continue;
			}

			// if we're not inside the same warp, process all WARP_SIZE * WARP_SIZE pairs inside the warp
			// otherwise only process the lower half
			// indexA >= indexB <=> localIndexA + blockOffsetA >= localIndexB + blockOffsetB <=> localIndexA >= localIndexB
			// (this only works for NUM_WARPS == NUM_LOCAL_STORAGE_WARPS!!!)
			if( blockPairType == BPT_SAME_BLOCK && localIndexB >= localIndexA ) {
				continue;
			}

#		ifndef CUDA_HW_CACHE_ONLY
			processMoleculePair( threadIndex, localIndexB, moleculeA );
#		else
			processMoleculePair( threadIndex, blockOffsetB + localIndexB, moleculeA );
#		endif
		}

		__syncthreads();
#	endif
#endif
		// write moleculeB back
		if( threadIndex < numMoleculesInBlockB ) {
			moleculeLocalStorage.commit( threadIndex, indexB );
		}
		__syncthreads();
	}

	__device__ void processCellPair( const int threadIndex, const CellInfoEx & cellA, const CellInfoEx & cellB) {
		const uint numBlocksA = iceil<uint>( cellA.length, blockSize );
		const uint numBlocksB = iceil<uint>( cellB.length, localStorageBlockSize );

		for( uint blockIndexA = 0 ; blockIndexA < numBlocksA ; blockIndexA++ ) {
			const uint numMoleculesInBlockA = (blockIndexA < numBlocksA - 1) ? blockSize : shiftedMod( cellA.length, blockSize );
			const uint blockOffsetA = cellA.startIndex + blockIndexA * blockSize;

			StorageMolecule moleculeA;

			const int indexA = blockOffsetA + threadIndex;
			if( threadIndex < numMoleculesInBlockA ) {
				moleculeA.load( indexA );
			}

			for( uint blockIndexB = 0 ; blockIndexB < numBlocksB ; blockIndexB++ ) {
				const uint numMoleculesInBlockB = (blockIndexB < numBlocksB - 1) ? localStorageBlockSize : shiftedMod( cellB.length, localStorageBlockSize );
				const uint blockOffsetB = cellB.startIndex + blockIndexB * localStorageBlockSize;

				processBlock<BPT_UNRELATED>(
						threadIndex,
						numMoleculesInBlockA,
						numMoleculesInBlockB,
						blockOffsetB,
						moleculeA
					);
			}

			// push A data back
			if( threadIndex < numMoleculesInBlockA ) {
				moleculeA.store();
			}
		}
	}

	__device__ void processCell(const int threadIndex, const CellInfoEx cell) {
		const uint numBlocks = iceil<uint>( cell.length, blockSize );

		for( uint blockIndexA = 0 ; blockIndexA < numBlocks ; blockIndexA++ ) {
			const uint numMoleculesInBlockA = (blockIndexA < numBlocks - 1) ? blockSize : shiftedMod( cell.length, blockSize );
			const uint blockOffsetA = cell.startIndex + blockIndexA * blockSize;

			StorageMolecule moleculeA;

			const uint indexA = blockOffsetA + threadIndex;
			if( threadIndex < numMoleculesInBlockA ) {
				moleculeA.load( indexA );
			}

			processBlock<BPT_SAME_BLOCK>(
					threadIndex,
					numMoleculesInBlockA,
					numMoleculesInBlockA,
					blockOffsetA,
					moleculeA
				);

			//assert: everything is synced here because of the __syncthreads calls in processBlock
			for( uint blockIndexB = 0 ; blockIndexB < blockIndexA; blockIndexB++ ) {
				// blockIndexB < blockIndexA - 1  < numBlocks - 1 implies numCellsInBlock = BLOCK_SIZE
				const uint numMoleculesInBlockB = blockSize;
				const uint blockOffsetB = cell.startIndex + blockIndexB * blockSize;

				processBlock<BPT_UNRELATED>(
						threadIndex,
						numMoleculesInBlockA,
						numMoleculesInBlockB,
						blockOffsetB,
						moleculeA
					);
			}

			// push A data back
			if( threadIndex < numMoleculesInBlockA ) {
				moleculeA.store();
			}
		}
	}
};





